<!DOCTYPE html>
<html>
    <head>
        <title>Deep In Motion : Papers published on the project</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">Deep In Motion</a></span>
                            </li>
                                                    <li>
                                <span><a href="Deep-In-Motion-Home_401868245.html">Deep In Motion Home</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            Deep In Motion : Papers published on the project
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                        
        
    
    
        
    
        
        
            Created by <span class='author'> Pål Haugen</span>, last updated by <span class='editor'> Inga Strümke</span> on 18.08.2025
    
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <div class="table-wrap"><table class="relative-table wrapped confluenceTable" style="text-decoration: none;width: 95.46089%;"><colgroup><col style="width: 33.065105%;"/><col style="width: 42.79444%;"/><col style="width: 14.630578%;"/><col style="width: 5.413314%;"/><col style="width: 4.023409%;"/></colgroup><tbody class=""><tr class=""><td class="confluenceTd"><p><strong>Authors</strong></p></td><td class="confluenceTd"><p><strong>Title</strong></p></td><td class="confluenceTd"><p><strong>Publication</strong></p></td><td class="confluenceTd"><p><strong>Volume</strong></p></td><td class="confluenceTd"><p><strong>Year</strong></p></td></tr><tr class=""><td class="confluenceTd"><p><strong>Tempel, Felix; Ihlen, Espen Alexander F; Strümke, Inga; </strong></p></td><td class="confluenceTd"><p>AutoGCN-Towards Generic Human Activity Recognition with Neural Architecture Search</p></td><td class="confluenceTd"><p>IEEE Access</p></td><td class="confluenceTd"><p><br/></p></td><td class="confluenceTd"><p>2024</p></td></tr><tr class=""><td class="confluenceTd"><p><strong>Tempel, Felix; Ihlen, Espen Alexander F; Strümke, Inga; </strong></p></td><td class="confluenceTd"><p>Lightweight Neural Architecture Search for Cerebral Palsy Detection</p></td><td class="confluenceTd"><p>IEEE SSCI 2025</p></td><td class="confluenceTd"><p><br/></p></td><td class="confluenceTd"><p>2025</p></td></tr><tr class=""><td class="confluenceTd"><p><strong>Tempel, Felix; Ihlen, Espen Alexander F; Adde, Lars; Strümke, Inga; </strong></p></td><td class="confluenceTd"><p>Explaining Human Activity Recognition with SHAP: Validating insights with perturbation and quantitative measures</p></td><td class="confluenceTd"><p>Computers in Biology and Medicine</p></td><td class="confluenceTd"><p>188</p></td><td class="confluenceTd"><p>2025</p></td></tr><tr><td class="confluenceTd"><p><strong>Tempel, Felix; Groos, Daniel; Ihlen, Espen Alexander F; Adde, Lars; Strümke, Inga; </strong></p></td><td class="confluenceTd"><p>Choose Your Explanation: A Comparison of SHAP and GradCAM in Human Activity Recognition</p></td><td class="confluenceTd"><p>arXiv preprint arXiv:2412.16003</p></td><td class="confluenceTd"><p><br/></p></td><td class="confluenceTd"><p>2024</p></td></tr><tr><td class="confluenceTd"><p><strong>Groos, Daniel; Adde, Lars; Aubert, Sindre; et. al</strong></p></td><td class="confluenceTd"><p>Development and Validation of a Deep Learning Method to Predict Cerebral Palsy<br/>From Spontaneous Movements in Infants at High Risk</p></td><td class="confluenceTd"><p>JAMA</p></td><td class="confluenceTd"><p><br/></p></td><td class="confluenceTd"><p>2022</p></td></tr><tr class=""><td class="confluenceTd"><strong>Kimji N Pellano, Inga Strümke, Daniel Groos, Lars Adde, Pål Haugen, Espen Alexander F Ihlen</strong></td><td class="confluenceTd">Towards Biomarker Discovery for Early Cerebral Palsy Detection: Evaluating Explanations Through Kinematic Perturbations</td><td class="confluenceTd">arXiv preprint: arXiv:2503.16452</td><td class="confluenceTd"><br/></td><td class="confluenceTd">2025</td></tr><tr><td class="confluenceTd"><strong>Kimji N Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F Ihlen</strong></td><td class="confluenceTd">Evaluating explainable ai methods in deep learning models for early detection of cerebral palsy</td><td class="confluenceTd">IEEE Access</td><td class="confluenceTd"><br/></td><td class="confluenceTd">2025</td></tr><tr><td class="confluenceTd"><strong>Kimji N Pellano, Inga Strümke, Espen AF Ihlen</strong></td><td class="confluenceTd">From movements to metrics: Evaluating explainable ai methods in skeleton-based human activity recognition</td><td class="confluenceTd">MDPI Sensors</td><td class="confluenceTd"><br/></td><td class="confluenceTd">2024</td></tr><tr><td class="confluenceTd"><strong>Reda Hassan, Nhien Nguyen, Stine Rasdal Finserås, Lars Adde, Inga Strümke, Ragnhild Støen</strong></td><td class="confluenceTd">Unlocking the black box: Enhancing human-AI collaboration in high-stakes healthcare scenarios through explainable AI</td><td class="confluenceTd">Technological Forecasting and Social Change</td><td class="confluenceTd">219</td><td class="confluenceTd">2025</td></tr><tr><td class="confluenceTd"><strong>Tor Sporsem, Stine Rasdal Finserås, Inga Strümke</strong></td><td class="confluenceTd">Clinicians don't know what explanations they need: A case study on eliciting AI software explainability requirements</td><td class="confluenceTd">arXiv preprint arXiv:2501.09592</td><td class="confluenceTd"><br/></td><td class="confluenceTd">2025</td></tr><tr><td class="confluenceTd"><strong>...</strong></td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td></tr></tbody></table></div><p><br/></p><h1 class="meta-article-title" id="Paperspublishedontheproject-DevelopmentandValidationofaDeepLearningMethodtoPredictCerebralPalsyFromSpontaneousMovementsinInfantsatHighRisk"><a class="external-link" href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2794119" rel="nofollow">Development and Validation of a Deep Learning Method to Predict Cerebral Palsy From Spontaneous Movements in Infants at High Risk</a></h1>
                    </div>

                                                            <div class="pageSection group">
                        <div class="pageSectionHeader">
                            <h2 id="attachments" class="pageSectionTitle">Attachments:</h2>
                        </div>

                        <div class="greybox" align="left">
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/403309062/423690380.csv">citations.csv</a> (text/csv)
                                <br/>
                                                    </div>
                    </div>
                    
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on 19.08.2025 14:20 CEST</p>
                    <div id="footer-logo"><a href="https://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
