<!DOCTYPE html>
<html>
    <head>
        <title>Deep In Motion : 16.8 Feature influence</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">Deep In Motion</a></span>
                            </li>
                                                    <li>
                                <span><a href="Deep-In-Motion-Home_401868245.html">Deep In Motion Home</a></span>
                            </li>
                                                    <li>
                                <span><a href="Index-of-tables_403308818.html">Index of tables</a></span>
                            </li>
                                                    <li>
                                <span><a href="Evaluation_403308870.html">Evaluation</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            Deep In Motion : 16.8 Feature influence
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                        
        
    
    
        
    
        
        
            Created by <span class='author'> Felix Tempel</span>, last updated by <span class='editor'> Daniel Groos</span> on 20.08.2025
    
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <p><strong>Requirements</strong></p><ul><li data-uuid="f22d884a-c25b-42db-823c-67268323b1f1">The manufacturer has considered, especially for tabular data for individual data sets, to have the model show the features that particularly influenced the decision <a class="external-link" href="https://github.com/johner-institut/ai-guideline/blob/master/Guideline-AI-Medical-Devices_EN.md#user-content-fn-C.4.c.2-b6daf829538eb59c530c6a09d03d7ff9" rel="nofollow" style=""><sup>26</sup></a>. </li></ul><p><strong>Summary</strong></p><p>The model from Groos et al. input includes interpretable feature groups:</p><ul><li><p>Position (P), Velocity (V), and Bone (B)</p></li></ul><p>These are processed through <strong>separate model streams</strong>, allowing targeted future attribution analysis.</p><p>In the current implementation from Groos et al., CAM or Grad-CAM is implemented for global model explainability.</p><p><br/></p><p>In <a href="attachments/403309793/428344941.pdf" data-linked-resource-id="428344941" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="tempel_ShapGCN.pdf" data-nice-type="PDF Document" data-linked-resource-content-type="application/pdf" data-linked-resource-container-id="403309793" data-linked-resource-container-version="2">(Tempel et al.)</a>, the single model was explained using SHAP:</p><p><strong>Input feature groups</strong>:</p><ul style="text-decoration: none;"><li data-uuid="72a11fb3-6a94-4880-9aa1-c6975eab3e87"><p>Joint positions (J)</p></li><li data-uuid="63adecea-80b1-4279-9b21-33e71509c00c"><p>Velocity (V)</p></li><li data-uuid="fa8a6bc6-4606-4980-8895-6ac75f7205e4"><p>Bone orientation and lengths (B)</p></li><li data-uuid="608b15cd-69c5-4c16-971c-fab5cfd1f6d7"><p>Acceleration (A)</p></li></ul><p>These features were processed via distinct model branches and <strong>explained post hoc using SHAP</strong> to attribute influence to each feature at both global and local levels.</p><p style="text-decoration: none;"><strong>Global Feature Importance</strong></p><ul><li data-uuid="85ab7d36-474c-4551-b91a-79e1c196e3fc"><p><strong>SHAP beeswarm plots</strong> were used to summarize global feature contributions across the validation dataset.</p></li></ul><p><strong>Local Feature Importance</strong></p><ul style="text-decoration: none;"><li data-uuid="f9b0f1c3-5bc7-444f-a6f0-76b4597eeb95"><p>For individual infant predictions, <strong>SHAP values were aggregated by body key point and mapped back onto the skeleton</strong> to provide intuitive visual explanations.</p></li></ul><p>To validate the explanation fidelity, a <strong>perturbation-based test </strong>was implemented:</p><ul style="text-decoration: none;"><li data-uuid="e2bb9b28-2b83-4f55-a7e6-349340467f97"><p>Key points identified as important via SHAP were perturbed in the model's edge matrix.</p></li><li data-uuid="5ea6d621-9141-4743-a1a9-9a2c220f6d66"><p>Perturbing <strong>top-ranked key points caused a significant drop in model sensitivity (down to 37%)</strong>, while perturbing SHAP-irrelevant points had a much lower effect.</p></li><li data-uuid="cba0c58d-51fe-406f-ae8e-025934a78211"><p><strong>Prediction Gap Index (PGI)</strong> and <strong>Prediction Gap Unimportance (PGU)</strong> metrics were calculated to quantify explanation faithfulness.</p></li></ul>
                    </div>

                                        
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on 19.09.2025 09:41 CEST</p>
                    <div id="footer-logo"><a href="https://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
